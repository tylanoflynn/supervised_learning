{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- The os module has a perfect method to list files in a directory.\n",
    "- Pandas json normalize could work here but is not necessary to convert the JSON data to a dataframe.\n",
    "- You may need a nested for-loop to access each sale!\n",
    "- We've put a lot of time into creating the structure of this repository, and it's a good example for future projects.  In the file functions_variables.py, there is an example function that you can import and use.  If you have any variables, functions or classes that you want to make, they can be put in the functions_variables.py file and imported into a notebook.  Note that only .py files can be imported into a notebook. If you want to import everything from a .py file, you can use the following:\n",
    "```python\n",
    "from functions_variables import *\n",
    "```\n",
    "If you just import functions_variables, then each object from the file will need to be prepended with \"functions_variables\"\\\n",
    "Using this .py file will keep your notebooks very organized and make it easier to reuse code between notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (this is not an exhaustive list of libraries)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from pprint import pprint\n",
    "from functions_variables import encode_tags\n",
    "\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8159 entries, 0 to 41\n",
      "Data columns (total 27 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   branding_name          7910 non-null   object \n",
      " 1   community              5 non-null      object \n",
      " 2   baths                  7980 non-null   float64\n",
      " 3   baths_1qtr             0 non-null      object \n",
      " 4   baths_3qr              0 non-null      object \n",
      " 5   baths_full             7311 non-null   object \n",
      " 6   baths_half             2281 non-null   object \n",
      " 7   is_coming_soon         0 non-null      object \n",
      " 8   is_contingent          0 non-null      object \n",
      " 9   last_update_date       8125 non-null   object \n",
      " 10  show_contact_an_agent  8159 non-null   bool   \n",
      " 11  list_date              7752 non-null   object \n",
      " 12  list_price             7721 non-null   object \n",
      " 13  listing_id             7752 non-null   object \n",
      " 14  city                   8154 non-null   object \n",
      " 15  lat                    7909 non-null   object \n",
      " 16  lon                    7909 non-null   object \n",
      " 17  line                   8144 non-null   object \n",
      " 18  postal_code            8159 non-null   object \n",
      " 19  state                  8159 non-null   object \n",
      " 20  state_code             8159 non-null   object \n",
      " 21  open_houses            0 non-null      object \n",
      " 22  price_reduced_amount   2484 non-null   object \n",
      " 23  brand_name             7673 non-null   object \n",
      " 24  property_id            8159 non-null   object \n",
      " 25  status                 8159 non-null   object \n",
      " 26  tags                   7638 non-null   object \n",
      "dtypes: bool(1), float64(1), object(25)\n",
      "memory usage: 1.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# ChatGPT \n",
    "def get_nested_value(data, *keys):\n",
    "    try:\n",
    "        for key in keys:\n",
    "            data = data[key]\n",
    "        return data\n",
    "    except (TypeError, KeyError):\n",
    "        return None\n",
    "\n",
    "#make list of file names in data folder\n",
    "file_list = os.listdir('../data')\n",
    "\n",
    "# Create a dataframe to store all data\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "i = 0\n",
    "\n",
    "#loop through filenames in list \n",
    "for file in file_list:\n",
    "    i += 1\n",
    "    print(i)\n",
    "    try:\n",
    "        #load json object\n",
    "        with open('../data/' + file) as f:\n",
    "            nested_json = json.load(f)\n",
    "            response_data = nested_json['data']['results']\n",
    "            # List to store data from file\n",
    "            extracted_data = []\n",
    "            for result in response_data:\n",
    "                row = {\n",
    "                    'branding_name': nested_json['data']['results'][0]['branding'][0]['name'],  \n",
    "                    'baths': get_nested_value(result, 'description', 'baths'),\n",
    "                    'baths_1qtr': get_nested_value(result, 'description', 'baths_1qtr'),\n",
    "                    'baths_3qr': get_nested_value(result, 'description', 'baths_3qr'),\n",
    "                    'baths_full': get_nested_value(result, 'description', 'baths_full'),\n",
    "                    'baths_half': get_nested_value(result, 'description', 'baths_half'),                          \n",
    "                    # Still need to add ('beds','garage','lot_sqft','name','sold_date','sold_price', 'sqft', 'stories', 'sub_type', 'type', 'year_built')\n",
    "                    \n",
    "                    'is_coming_soon': get_nested_value(result, 'flags', 'is_coming_soon'),\n",
    "                    'is_contingent': get_nested_value(result, 'flags', 'is_contingent'),\n",
    "                    # Still need to add ('is_for_rent', 'is_foreclosure', 'is_new_construction', 'is_new_listing', 'is_pending', 'is_plan', 'is_price_reduced', 'is_subdivision')\n",
    "                    \n",
    "                    'last_update_date': get_nested_value(result, 'last_update_date'),\n",
    "                    'show_contact_an_agent': get_nested_value(result, 'lead_attributes', 'show_contact_an_agent'),\n",
    "                    'list_date': get_nested_value(result, 'list_date'),\n",
    "                    'list_price': get_nested_value(result, 'list_price'),\n",
    "                    'listing_id': get_nested_value(result, 'listing_id'),\n",
    "                    'city': get_nested_value(result, 'location', 'address', 'city'),\n",
    "                    'lat': get_nested_value(result, 'location', 'address', 'coordinate', 'lat'),\n",
    "                    'lon': get_nested_value(result, 'location', 'address', 'coordinate', 'lon'),\n",
    "                    'line': get_nested_value(result, 'location', 'address', 'line'),\n",
    "                    'postal_code': get_nested_value(result, 'location', 'address', 'postal_code'),\n",
    "                    'state': get_nested_value(result, 'location', 'address', 'state'),\n",
    "                    'state_code': get_nested_value(result, 'location', 'address', 'state_code'),\n",
    "                    'open_houses': get_nested_value(result, 'open_houses'),\n",
    "                    'price_reduced_amount': get_nested_value(result, 'price_reduced_amount'),\n",
    "                    'brand_name': get_nested_value(result, 'products', 'brand_name'),\n",
    "                    'property_id': get_nested_value(result, 'property_id'),\n",
    "                    'status': get_nested_value(result, 'status'),\n",
    "                    'tags': get_nested_value(result, 'tags'),\n",
    "                }\n",
    "                extracted_data.append(row)\n",
    "        extracted_dataframe = pd.DataFrame(extracted_data).drop_duplicates(\"property_id\")\n",
    "        all_data = pd.concat([all_data, extracted_dataframe])\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(all_data.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7065 entries, 0 to 41\n",
      "Data columns (total 25 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   branding_name          6958 non-null   object \n",
      " 1   baths                  6915 non-null   float64\n",
      " 2   baths_1qtr             0 non-null      object \n",
      " 3   baths_3qr              0 non-null      object \n",
      " 4   baths_full             6414 non-null   object \n",
      " 5   baths_half             1986 non-null   object \n",
      " 6   is_coming_soon         0 non-null      object \n",
      " 7   is_contingent          0 non-null      object \n",
      " 8   last_update_date       7038 non-null   object \n",
      " 9   show_contact_an_agent  7065 non-null   bool   \n",
      " 10  list_date              6765 non-null   object \n",
      " 11  list_price             6739 non-null   object \n",
      " 12  listing_id             6765 non-null   object \n",
      " 13  city                   7063 non-null   object \n",
      " 14  lat                    6879 non-null   object \n",
      " 15  lon                    6879 non-null   object \n",
      " 16  line                   7052 non-null   object \n",
      " 17  postal_code            7065 non-null   object \n",
      " 18  state                  7065 non-null   object \n",
      " 19  state_code             7065 non-null   object \n",
      " 20  open_houses            0 non-null      object \n",
      " 21  price_reduced_amount   2209 non-null   object \n",
      " 22  brand_name             6734 non-null   object \n",
      " 23  property_id            7065 non-null   object \n",
      " 24  status                 7065 non-null   object \n",
      "dtypes: bool(1), float64(1), object(23)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "all_data.iloc[:, :-1].drop_duplicates().info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_data = all_data\n",
    "\n",
    "string_data.loc[:, 'tags'] = string_data['tags'].apply(lambda x: tags_to_string(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 42 entries, 0 to 41\n",
      "Data columns (total 27 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   branding_name          42 non-null     object \n",
      " 1   community              0 non-null      object \n",
      " 2   baths                  42 non-null     int64  \n",
      " 3   baths_1qtr             0 non-null      object \n",
      " 4   baths_3qr              0 non-null      object \n",
      " 5   baths_full             39 non-null     float64\n",
      " 6   baths_half             9 non-null      float64\n",
      " 7   is_coming_soon         0 non-null      object \n",
      " 8   is_contingent          0 non-null      object \n",
      " 9   last_update_date       42 non-null     object \n",
      " 10  show_contact_an_agent  42 non-null     bool   \n",
      " 11  list_date              42 non-null     object \n",
      " 12  list_price             42 non-null     int64  \n",
      " 13  listing_id             42 non-null     object \n",
      " 14  city                   42 non-null     object \n",
      " 15  lat                    42 non-null     float64\n",
      " 16  lon                    42 non-null     float64\n",
      " 17  line                   42 non-null     object \n",
      " 18  postal_code            42 non-null     object \n",
      " 19  state                  42 non-null     object \n",
      " 20  state_code             42 non-null     object \n",
      " 21  open_houses            0 non-null      object \n",
      " 22  price_reduced_amount   8 non-null      float64\n",
      " 23  brand_name             42 non-null     object \n",
      " 24  property_id            42 non-null     object \n",
      " 25  status                 42 non-null     object \n",
      " 26  tags                   42 non-null     object \n",
      "dtypes: bool(1), float64(5), int64(2), object(19)\n",
      "memory usage: 8.9+ KB\n"
     ]
    }
   ],
   "source": [
    "string_data.drop_duplicates().info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, ensure that you have all sales in a dataframe.\n",
    "- Is each cell one value, or do some cells have lists?\n",
    "- Maybe the \"tags\" will help create some features.\n",
    "- What are the data types of each column?\n",
    "- Some sales may not actually include the sale price.  These rows should be dropped.\n",
    "- Some sales don't include the property type.\n",
    "- There are a lot of None values.  Should these be dropped or replaced with something?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and concatenate data here\n",
    "# drop or replace values as necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the fact that with tags, there are a lot of categorical variables.\n",
    "- How many columns would we have if we OHE tags, city and state?\n",
    "- Perhaps we can get rid of tags that have a low frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHE categorical variables here\n",
    "# tags will have to be done manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sales will vary drastically between cities and states.  Is there a way to keep information about which city it is without OHE such as using central tendency?\n",
    "- Could we label encode or ordinal encode?  Yes, but this may have undesirable effects, giving nominal data ordinal values.\n",
    "- If you replace cities or states with numerical values, make sure that the data is split so that we don't leak data into the training selection. This is a great time to train test split. Compute on the training data, and join these values to the test data\n",
    "- Drop columns that aren't needed.\n",
    "- Don't keep the list price because it will be too close to the sale price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform train test split here\n",
    "# do something with state and city\n",
    "# drop any other not needed columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STRETCH**\n",
    "\n",
    "- You're not limited to just using the data provided to you. Think/ do some research about other features that might be useful to predict housing prices. \n",
    "- Can you import and join this data? Make sure you do any necessary preprocessing and make sure it is joined correctly.\n",
    "- Example suggestion: could mortgage interest rates in the year of the listing affect the price? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import, join and preprocess new data here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember all of the EDA that you've been learning about?  Now is a perfect time for it!\n",
    "- Look at distributions of numerical variables to see the shape of the data and detect outliers.\n",
    "- Scatterplots of a numerical variable and the target go a long way to show correlations.\n",
    "- A heatmap will help detect highly correlated features, and we don't want these.\n",
    "- Is there any overlap in any of the features? (redundant information, like number of this or that room...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform EDA here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now is a great time to scale the data and save it once it's preprocessed.\n",
    "- You can save it in your data folder, but you may want to make a new `processed/` subfolder to keep it organized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
